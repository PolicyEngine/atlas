// PBIF Application Content
// This file is auto-generated by scripts/build_application_content.py
// DO NOT EDIT DIRECTLY - edit the source markdown files in docs/pbif/responses/

export const executiveSummaryContent = `
## Section 1: Executive Summary

### 1.1 Executive Summary

> **Question:** In a concise summary, describe the core problem your project addresses, the proposed technical solution, the target beneficiaries, and the anticipated impact.

**Word count: 250/250**

Organizations helping Americans access benefits face the same crisis: policy documents are scattered, unclear, or disappearing. Every caseworker, navigator tool, and research group must independently build and maintain document libraries—duplicating effort while links break and documents vanish. As the leading open-source rules engine powering tools helping over 100,000 Americans, PolicyEngine has seen how this foundational problem cripples the entire ecosystem. PolicyEngine Atlas solves this once, for everyone.

Building on pilots with the Atlanta Fed, Atlas will be the first comprehensive, AI-powered archive of safety net policy documents. We'll retrieve, store, and continuously update thousands of statutes, regulations, and manuals across 50 states—preventing the link rot and document loss plaguing benefit delivery.

Atlas goes beyond preservation. By integrating with PolicyEngine's proven rules engine, we transform static documents into a semantic knowledge graph revealing connections between programs and jurisdictions. This enables caseworkers to verify eligibility pathways with source documents, researchers to trace policy evolution, and AI tools to access authoritative sources through our web app, API, and MCP server.

To reduce administrative burden, we'll introduce the Clarity Index—a scoring system that combines human expertise with AI to analyze Atlas's archived documents and identify which policy language causes errors and delays. Strategic subgrants to government-connected organizations help agencies learn from successful peers, transforming insights into clearer policy communication.

PolicyEngine Atlas creates essential infrastructure for safety net transformation. By providing universal access to clear, computable, authoritative policy documents, we enable the entire ecosystem—from applicants to policymakers—to make our fragmented benefit system work as one.

### 1.2 Stage of Development

> **Question:** If there are current or planned users, describe who they are and how they are using the system.

**Word count: 248/250**

PolicyEngine Atlas is at proof of concept stage. We've demonstrated feasibility through collaboration with the Atlanta Fed and Georgia Center for Opportunity, storing 237 federal and North Carolina documents in GitHub repositories (github.com/policyengine/us-sources and github.com/policyengine/us-nc-sources) covering tax credits, SNAP, LIHEAP, TANF, CCDF, Medicaid, and CHIP. This pilot proves document collection works, but the full Atlas system—automated monitoring, Clarity Index, and production API—remains to be built.

Current partners are integrating our pilot repositories. The Atlanta Fed, Georgia Center for Opportunity, and PolicyEngine are now implementing citations to these document collections in our production systems. While not yet live, this validates demand for authoritative sources. Attached letters of support from organizations including Benefit Kitchen and Urban Institute indicate significant benefits of this system. Our interactive mockup demonstrates the envisioned user experience: policyengine.github.io/atlas

PolicyEngine's existing infrastructure enables rapid Atlas development. Congress and top universities use our policy microsimulation tools, we serve over 100,000 Americans through our rules engine, and operate a production API. We've already launched LLM features that explain eligibility rules by combining our rules engine with AI (policyengine.org/us/research/us-household-ai), demonstrating our capability to transform policy documents into accessible explanations. This proven foundation positions us to deploy the full Atlas system within PBIF's 12-month requirement.

Our team brings proven expertise: CEO Max Ghenis and data scientist Ben Ogorek founded Google's People Analytics Data Science team; CTO Nikhil Woodruff built our AI features; economist Pavel Makarchuk directed our US rules engine and the Atlanta Fed/GCO pilot. With PBIF support we'll scale nationwide.
`;

export const valuePropositionContent = `
## Section 2: Value Proposition

### 2.1 Problem Statement

> **Question:** Clearly articulate the specific problem or challenge your initiative aims to address and how it relates to recent changes in federal policy or funding changes. Provide supporting data or evidence to demonstrate the urgency and significance of this problem - and how you've validated it with staff and/or beneficiaries. Is this an area where non-AI solutions do not already offer effective, fit-for-purpose, affordable approaches?

**Word count: 249/250**

Organizations helping Americans access benefits face an infrastructure crisis: no platform connects scattered policy documents into a coherent system. Every caseworker, navigator tool, and research group works with fragments of the policy landscape—unable to see connections across programs or jurisdictions. When Casetext shut down, thousands of legal aid organizations lost document access overnight. This fragmentation forces each organization to solve the same problem separately, wasting resources.

Rules-as-code developers cannot establish authoritative sources for their calculations. While PolicyEngine cites over 2,500 policy URLs, these remain disconnected fragments rather than a semantic system. MyFriendBen and Benefit Navigator lack direct access to regulatory text behind eligibility determinations—verification requires digging through code rather than referencing documentation. Without a platform connecting computable policies to authoritative documents, tools cannot earn government trust.

The fragmentation also hides critical eligibility pathways. Categorical eligibility chains exist across programs—TANF enables SNAP, SNAP qualifies for Lifeline, LIHEAP unlocks weatherization—but remain invisible in traditional document search. Caseworkers cannot discover these connections systematically, meaning families miss benefits they qualify for because policies aren't computationally linked.

Meanwhile, unclear policy language drives administrative burden costing billions annually. GAO calls complex regulations "inherently error-prone," creating barriers preventing eligible families from accessing benefits. Yet agencies cannot learn which language patterns work because no infrastructure enables comparison across jurisdictions. States repeat mistakes; improvement remains guesswork.

As AI tools increasingly assist with benefit navigation, the lack of authoritative sources becomes critical. Large language models cannot reliably explain benefit rules without verified documentation, limiting their potential to help families.

### 2.2 Solution & Target Beneficiaries

> **Question:** How does your solution address the problem? Who are the primary beneficiaries of this project? How are they involved in the project?

**Word count: 246/250**

PolicyEngine Atlas solves the infrastructure crisis once for everyone. Instead of each organization maintaining separate document libraries, we create a comprehensive, AI-powered archive serving the entire ecosystem. We retrieve, store, and continuously update thousands of statutes, regulations, and manuals across 50 states. By integrating with PolicyEngine's proven rules engine, we transform static documents into a semantic knowledge graph revealing program connections, letting organizations stop duplicating effort and focus on helping families.

Rules-as-code developers gain authoritative sources to prove accuracy. PolicyEngine, MyFriendBen, and Benefit Navigator can cite computable policies linked to official documents, while our semantic layer reveals categorical eligibility chains—like TANF enabling SNAP which qualifies for Lifeline—invisible in traditional search. When tools reference exact regulatory text, governments trust them for official use.

Direct service organizations save massive resources through our integrated platform. MyFriendBen and Benefit Navigator accelerate feature deployment, while caseworkers can verify PolicyEngine's categorical eligibility rules against actual source documents—seeing regulations connecting SSI to Medicaid or SNAP to school meals. The Clarity Index identifies error-causing policy language, helping organizations provide clearer guidance. Our MCP server enables AI assistants to access authoritative sources, preventing hallucination.

Government agencies improve policy communication systematically through the Clarity Index, which analyzes Atlas's archived documents using human expertise and AI to identify error-causing language. When one state's simplified language reduces errors, others adopt those proven approaches through our platform. Strategic subgrants to government-connected organizations ensure these insights become clearer communication—not policy changes—ultimately benefiting families through reduced administrative burden and fewer denials.

### 2.3 Proposed Benefit and Impact Evaluation

> **Question:** What will change as a result of your project? What specific, measurable, achievable, relevant, and time-bound metrics will you use? How many people do you expect your solution to influence over what time period? Provide baseline data if available.

**Word count: 224/250**

Our evaluation measures progress toward making policies accessible, clear, and computable. For accessibility, we track document growth from 237 baseline to 5,000 by Year 2, Atlas API usage reaching thousands of monthly lookups, and partner integrations expanding from four current PolicyEngine customers to dozens using Atlas for source verification.

For clarity, our Clarity Index scores all 5,000 documents, identifying problematic language patterns. We'll measure whether agencies adopt simpler language after seeing peer comparisons, track reduction in caseworker interpretation errors, and document time saved answering eligibility questions. Case studies will show how organizations using Atlas provide more accurate guidance—like caseworkers correctly explaining SNAP-to-Lifeline categorical eligibility.

For computability, we evaluate how Atlas accelerates rules-as-code development. We'll publish studies showing how documents aid automating RAC processes and measure usage by other RAC providers (Atlanta Fed, GCO, Urban, NBER, Benefit Kitchen) building on our infrastructure. Success metrics include reduced time encoding new policies, increased accuracy of rules verified against sources, and API adoption by RAC developers.

We'll budget for independent Year 2 evaluation assessing system-level impact: governments adopting clearer policy language based on Clarity findings, benefit screeners confidently embedding Atlas on their sites, agencies contributing documents directly to Atlas, and ecosystem-wide adoption of open computational standards. The evaluator will survey partners, analyze usage data, and validate whether we've achieved our mission of making fragmented policies work as one.

### 2.4 Responsible Design and Use

> **Question:** What are the potential risks or unintended consequences of your solution (e.g., privacy, data protection, accuracy, clarity, or misuse)? How are you planning ahead to address these risks and ensure the tool is used appropriately, safely, and transparently?

**Word count: 242/250**

PolicyEngine Atlas implements comprehensive safeguards ensuring policies become accessible, clear, and computable equitably while protecting privacy and promoting open government.

Privacy protection begins with archiving only publicly available government documents and never collecting personal data, with system architecture actively preventing PII storage even if accidentally encountered. We maintain no user tracking beyond basic API metrics, ensuring complete privacy while complying with GDPR, CCPA, and government standards through regular security audits.

Equity considerations shape every design decision through comprehensive coverage of all states preventing geographic bias, free API access for nonprofits ensuring cost never prevents usage, and simplified interfaces accommodating limited technical expertise. Community partnerships ensure diverse perspectives guide development while we prioritize plain English documentation to maximize accessibility across all users.

Our bounty program leverages human expertise from trusted organizations like Urban Institute and Georgia Center for Opportunity to validate AI-extracted documents, creating multiple layers of quality assurance. This human-in-the-loop approach combines automated extraction with expert review, ensuring accuracy while building community ownership. Clear source labeling and extraction dates provide transparency, version control maintains complete audit trails, and open source code enables community verification with regular benchmarking against manual verification.

Misuse prevention balances openness with security through rate limiting that prevents abuse without impeding legitimate use and terms explicitly prohibiting fraud or harassment. Since documents are already public, we improve legitimate access without enabling new risks while continuous monitoring identifies suspicious patterns and maintains agency communication channels for rapid response to concerns.

### 2.5 Adoption and Path to Scale

> **Question:** How will your solution be implemented in real-world public benefit systems? What is your strategy for gaining adoption by government partners, community organizations, or beneficiaries? What steps will you take to ensure the solution is sustainable and scalable beyond a single site or pilot?

**Word count: 247/250**

Our adoption strategy leverages existing partnerships and proven demand to achieve nationwide scale within 12 months.

Immediate adoption begins with committed partners ready to integrate. MyFriendBen brings 3,500 monthly users in Colorado and North Carolina, expanding to Illinois and Massachusetts, while Benefit Navigator expands from LA County across California and beyond. Federal Reserve Atlanta integration lends government credibility. Georgetown and USC contribute to our rules engine and commit to adopting Atlas as they add documents, creating scholarly validation.

Accelerated growth occurs through organic referrals where satisfied users become advocates. Our open API enables self-service integration without bottlenecks. Conference presentations at Code for America Summit, APHSA, and NAWRS reach decision makers directly. Published case studies with documented time savings make the value proposition undeniable. Expansion to 40 states by month 9 creates network effects where coverage drives demand.

Scale achievement by month 12 establishes us as indispensable infrastructure. Complete coverage of 50 states plus federal programs provides unmatched comprehensiveness. Integration with 30 organizations creates ecosystem lock-in. Government partnerships formalize through procurement processes. Publication of our LLM benchmark drives AI developer adoption rapidly.

Built-in scaling mechanisms ensure sustainable growth. Serverless architecture handles demand spikes automatically. Crowdsourced corrections reduce per-document costs. API-first distribution enables unlimited integrations. Our free nonprofit tier removes financial barriers while premium support and enterprise contracts provide revenue for organizations needing guaranteed uptime.

Critical mass strategy focuses on Colorado, North Carolina, Illinois, Massachusetts, and California first, proving viability across diverse political and programmatic contexts before nationwide expansion.

### 2.6 Dissemination & Learning

> **Question:** How will you share your project's findings, lessons learned, and the AI solution itself (where appropriate, e.g., open-source code, public datasets) with the broader public benefits community and relevant stakeholders?

**Word count: 249/250**

We commit to radical transparency and knowledge sharing, ensuring all learnings benefit the entire ecosystem and can be replicated globally.

Strategic subgrants to MyFriendBen ($50k) and Benefit Navigator ($50k) enable real-world demonstration and dissemination. MyFriendBen validates Clarity Index scores across five states while leveraging Colorado agency connections. Benefit Navigator demonstrates rules-as-code value through government partnerships. Both partners generate case studies, validate methodology, and facilitate agency introductions for Atlas adoption.

Our open source approach publishes all code on GitHub under AGPL license in real-time, with comprehensive documentation enabling straightforward deployment anywhere. Weekly development updates keep the community informed while welcoming contributions that strengthen the system. This collaborative environment accelerates innovation beyond what any single organization could achieve.

Research publications share methodological innovations systematically: LLM accuracy benchmark methodology, policy document preservation best practices, partner case studies with quantified impacts, peer-reviewed publications on AI-powered government documentation, and our independent evaluator's comprehensive impact assessment.

Conference presentations reach key audiences: Code for America Summit for civic technologists, APHSA for human services professionals, NAWRS for welfare research, and academic conferences. We'll share findings about RAC acceleration, document preservation, and Clarity Index methodology validated through our demonstration partners.

Community support infrastructure includes monthly office hours, Discord for peer support, quarterly webinars, and an annual virtual summit starting Year 2. Educational resources span video tutorials, template code, university course materials, and policy brief templates.

Impact amplification leverages PolicyEngine's media channels, partner co-marketing, foundation networks, and government associations to ensure learnings reach everyone working to improve benefit access.
`;

export const technicalFeasibilityContent = `
## Section 3: Technical Feasibility

### 3.1 Solution Description

> **Question:** Describe your proposed technical solution. What problem does it solve, and how does it work in practice? Include: What specific AI or machine learning techniques/models will be used, and why? Will the tool function as a co-pilot for human users or as a fully automated system? What are the key checkpoints where human oversight will be required (if any)?

**Word count: 242/250**

PolicyEngine Atlas operates as an AI-powered co-pilot system where LLMs automate document processing while humans validate critical decisions through GitHub pull request reviews.

Our technical architecture combines LLMs for extraction with human oversight at key checkpoints. Document contributions flow through GitHub PRs ensuring review before publication. LLMs analyze file diffs to summarize policy changes. The web app uses semantic search combining document embeddings with PolicyEngine's rules metadata, enabling queries like "find all SNAP categorical eligibility pathways." API and MCP server provide programmatic access for tools and AI assistants.

The Clarity Index quantifies document ambiguity through innovative methodology. Human experts first rate select documents. Then we run each document through LLMs multiple times, asking them to encode policies for sample households. We define clarity as consistency across independent runs plus alignment with PolicyEngine's validated rules. When LLMs produce inconsistent interpretations, we identify the problematic passages—unclear income definitions, ambiguous timing requirements—and validate findings through human review. Results display at document and jurisdiction levels alongside error rates from SNAP QC data.

Three bounty programs ensure comprehensive coverage. First validates AI-extracted metadata from 2,500 existing PolicyEngine citations. Second verifies AI-discovered documents, particularly operational manuals containing implementation details. Third incentivizes partners to contribute missing documents that neither we nor AI can locate.

This human-AI collaboration transforms static documents into computable knowledge. Organizations access authoritative sources through our platform while the semantic layer reveals categorical eligibility chains, enabling accurate rules-as-code development and helping families access all qualifying benefits.

### 3.2 Data Strategy

#### Data Sources

> **Question:** What data sources will be used? Who owns the data? Do you already have data use agreements, or what is your plan to secure them?

**Word count: 250/250**

Our data sources encompass every publicly available policy document governing safety net programs across federal, state, and local jurisdictions. We systematically collect statutes from legislative websites and the OpenStates API, regulations from agency portals, program manuals containing critical implementation details, memos from departmental archives, and application forms from program websites. Each jurisdiction maintains these documents differently, requiring our AI crawlers to adapt to hundreds of unique website structures and document formats.

The federal layer includes documents from CMS for Medicaid, USDA for SNAP, HHS for TANF, SSA for disability programs, and Treasury for tax credits. State sources span welfare departments, health agencies, workforce development boards, and housing authorities across all 50 states plus DC and territories. Local sources focus on major metropolitan areas with unique benefit programs, particularly counties administering General Assistance or emergency aid programs.

Our collection methodology employs multiple approaches to ensure comprehensiveness. AI-powered crawlers using LLMs perform intelligent extraction, understanding context to identify relevant documents while filtering irrelevant content. Partner contributions from NBER, Urban Institute, and Georgetown provide specialized collections we might miss. Community submissions through GitHub allow corrections and additions from users discovering documents our automated systems haven't found.

Data quality assurance happens at multiple levels. Initial AI extraction undergoes human review for accuracy. Documents are checksummed to detect modifications. Metadata includes source URL, extraction date, and verification status. Version control tracks all changes over time. This multi-layered approach ensures that every document in our system is authentic, current, and properly attributed to its authoritative source.

#### Data Management

> **Question:** How will you ensure the data is sufficient, relevant, high-quality, and representative? What privacy and security safeguards will be in place (e.g., anonymization, encryption, access controls)?

**Word count: 246/250**

Our data management strategy ensures document integrity, accessibility, and preservation through multiple layers of governance and quality control. Every document entering our system undergoes verification through a transparent GitHub-based review process where human reviewers confirm accuracy of AI extraction, validate document authenticity, and ensure proper metadata attribution. This open review process creates accountability while enabling community contributions and corrections.

Version control forms the foundation of our preservation strategy. Using Git, we maintain complete history of every document change, enabling researchers to access any historical version and track policy evolution over time. Documents are cryptographically hashed to detect any modifications, and our distributed architecture across multiple Git remotes prevents single points of failure. Regular backups to cold storage ensure documents remain available even in catastrophic scenarios.

Data quality metrics guide our continuous improvement process. We track extraction accuracy rates, measuring how often human reviewers must correct AI-identified documents. Response time metrics ensure our API meets performance requirements for production systems. Coverage analysis identifies gaps in our collection, prioritizing jurisdictions or document types needing attention. User feedback loops enable rapid correction of any errors that reach production.

Access control balances openness with security. Read access remains open through our public API, supporting our mission of democratizing policy information. Write access requires authentication and follows strict contribution guidelines. Rate limiting prevents abuse while ensuring legitimate users have reliable access. Usage analytics help us understand access patterns without collecting personally identifiable information about users, maintaining privacy while improving service delivery.

### 3.3 Stakeholder Engagement

> **Question:** How are you working with government partners? Please provide letters of support. If no letters of support are available yet, how will you work to engage the right government partners? How, if at all, are you engaging other critical stakeholders like beneficiaries or frontline workers?

**Word count: 242/250**

Our stakeholder engagement strategy builds on strong existing partnerships while systematically expanding to serve the entire benefits ecosystem. Research institutions including Georgetown's Better Government Lab, Vanderbilt's Prenatal-to-3 Policy Impact Center, NBER, Urban Institute, and Benefit Kitchen committed to contribute specialized document collections and validate our approach, leveraging their existing benefit rule encodings to strengthen Atlas.

Direct service organizations MyFriendBen and Benefit Navigator receive $50,000 subgrants each for demonstration and dissemination. MyFriendBen validates Clarity Index scores across their 3,500 monthly users in Colorado and North Carolina, expanding to Illinois, Massachusetts, and Texas, while leveraging Colorado agency connections to facilitate government adoption. Benefit Navigator integrates Atlas into their Information Hub serving caseworkers across LA County, Riverside, Alameda, DC, Chicago, and New York, demonstrating rules-as-code value through their Riverside County Agentic AI pilot with Nava Labs.

Our bounty program incentivizes experts from trusted organizations like Urban Institute and Georgia Center for Opportunity to vet AI contributions and submit their own documents. Government partners like the Atlanta Federal Reserve integrate our system into their Policy Rules Database. Community advocates contribute through our open GitHub process, ensuring affected populations have direct input.

Continuous feedback loops ensure we remain responsive to user needs. MyFriendBen and Benefit Navigator provide monthly reports on Atlas integration, error rates, and user feedback. Academic partners share research findings. Government contacts communicate policy changes. This multi-stakeholder approach ensures Atlas serves everyone from individual caseworkers to federal agencies, creating lasting infrastructure for equitable benefit access.

### 3.4 Resources and Infrastructure

> **Question:** How will computational resources, software tools, cloud infrastructure, or other technical assets be secured or accessed? How, if at all, will the solution integrate with existing government systems?

**Word count: 244/250**

PolicyEngine Atlas builds on our existing Google Cloud Platform infrastructure, extending proven systems that already serve over 100,000 Americans through our rules engine. GCP provides auto-scaling compute for AI crawlers, Cloud Storage for documents, and managed services reducing operational complexity. Git repositories store documents with version history while GitHub Actions automate testing and deployment.

We're developing Atlas as a public good, accessible by any institution—government or otherwise—through open APIs and source code. Rather than requiring government systems to integrate with us, we provide multiple access methods: REST API for programmatic access, MCP server for AI assistants, web interface for caseworkers, and raw GitHub repositories for transparency. This flexibility lets agencies adopt Atlas at their own pace using their preferred integration approach.

Our outreach focuses on understanding government document management needs. Through partnerships with MyFriendBen's Colorado agency connections and Benefit Navigator's government relationships, we learn how agencies currently manage policy documents and what barriers prevent clearer communication. These insights shape Atlas development, ensuring our open source solution meets real government needs.

The integration with PolicyEngine's encoded rules creates unique value for government. When agencies see their documents connected to actual calculations affecting constituents, they understand how unclear language creates errors. Our semantic layer reveals how their policies interact with other programs, surfacing categorical eligibility pathways they may not realize exist. This combination of document management and rules-as-code demonstrates to agencies how modern infrastructure can reduce administrative burden while improving accuracy for the families they serve.

### 3.5 Scalability & Sustainability

> **Question:** How do you envision the long-term technical sustainability and scale of this project beyond the grant period?

**Word count: 249/250**

Since 2022, PolicyEngine has sustained an open source platform through balanced accessibility and revenue generation. We offer a free web app and Python package, charge $0.02 per household API request (near cost), and provide Docker images for self-hosting at no charge. This approach established us as the standard open source rules API, generating revenue through feature enhancements (encoding new policies), enterprise support, research projects, and subgrants.

Atlas follows this proven model. By 2027, operational costs will be minimal—primarily cloud storage and occasional document updates. Revenue streams mirror our successful formula: enterprise support for organizations needing guaranteed uptime, contracts to add new program types or jurisdictions, custom metadata integration with specific rules engines, and government contracts for onsite installations supporting clearer policy document assembly and dissemination.

Our mission drives accessibility-first pricing. Basic Atlas access remains free forever, ensuring small nonprofits can benefit. We charge only for premium features that large organizations value: guaranteed response times, custom integrations, priority support. Government agencies will increasingly seek our expertise to modernize their document management workflows, creating sustainable revenue while improving public services.

Technical efficiency ensures long-term viability. AI training costs decrease as models learn patterns. Community contributions through bounties reduce acquisition costs. Automated monitoring minimizes manual oversight. GitHub's infrastructure handles storage and versioning at minimal cost for 5,000 documents.

This sustainability model—proven through PolicyEngine's growth to serving over 100,000 Americans—ensures Atlas becomes permanent infrastructure. Free access drives adoption, premium services generate revenue, and our public benefit mission attracts continued foundation and government support.

### 3.6 Financial Viability

> **Question:** Tell us about your budget for this project. What percentage of your organization's annual operating budget does this grant represent? What are you intending to use this money for? Briefly describe your current funding diversification strategy.

**Word count: 241/250**

The total budget for PolicyEngine Atlas is $728,907 over two years. With PolicyEngine currently operating at $1 million annually, this grant of $364,454 per year represents approximately 27% of our expanded budget, demonstrating significant but manageable growth that allows continued development of our core rules engine while building Atlas infrastructure.

Budget allocation prioritizes people and partnerships. Personnel costs of $387,500 support 1.3 FTE across five team members. Strategic subgrants totaling $160,000 enable real-world demonstration through MyFriendBen ($50,000), Benefit Navigator ($50,000), Citizen Codex for UX design ($30,000), and an independent evaluator ($30,000). Infrastructure costs of $81,200 cover cloud computing, AI APIs, technical advisory services, search infrastructure, and document verification bounties. Travel and conferences add $5,132, with 15% indirect costs of $95,075.

PolicyEngine's funding trajectory shows strong growth. From our current $1 million budget in 2025, we project reaching $1.68 million in 2026 (68% growth) through confirmed grants: NSF ($200k of $300k total), MyFriendBen ($100k), and Arnold Ventures ($180k of $270k total). By 2027, we project $1.93 million through continued organic growth. This diversification includes NSF grants, Arnold Ventures support, NEO Philanthropy, subgrants from MyFriendBen, Gerald Huff Fund for Humanity, and contracts with Benefit Navigator.

Financial controls ensure responsible stewardship. Monthly reviews track spending against budget, quarterly reports to funders maintain transparency, and board oversight including financial experts guides strategic decisions. This PBIF investment creates lasting infrastructure while maintaining PolicyEngine's financial stability, ensuring Atlas becomes permanent public infrastructure regardless of future funding cycles.
`;
