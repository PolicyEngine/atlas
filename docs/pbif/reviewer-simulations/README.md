# PBIF Reviewer Simulation Instructions

## Overview
This folder contains simulated reviewer evaluations for the PolicyEngine Policy Library application to the Public Benefit Innovation Fund (PBIF) Summer 2025 Open Call.

**IMPORTANT SCOPE NOTE**: This is a **United States-only program** focused exclusively on US federal and state safety net programs. The Policy Library will archive documents for US jurisdictions only (50 states + DC + federal programs). While the open-source codebase could theoretically be adapted for other countries, this PBIF application and all proposed work is strictly limited to the United States.

## Review Context

### PBIF Evaluation Process
- **Round 1**: Eligibility screening (passed)
- **Round 2**: Comprehensive review by 3 expert evaluators (simulated here)
- **Round 3**: Technical deep dive with finalists

### Reviewer Types
We simulate three reviewers representing key perspectives:
1. **Government Technology Expert** - Former state IT director with benefits system experience
2. **Public Benefits Policy Expert** - Academic researcher focused on SNAP/Medicaid access
3. **AI/Product Strategy Expert** - Technical lead from previous PBIF grantee

## Materials for Review

### Primary Application Materials
- `/docs/pbif/one-pager.md` - Executive summary
- `/docs/pbif/project-narrative.md` - Full project narrative
- `/docs/pbif/budget-details.md` - Budget breakdown ($700,000 over 2 years)
- `/docs/pbif/letters/` - Letters of support from partners
- `/index.html` - Interactive mockup at policyengine.github.io/policy-library

### Key Partner Commitments (All US-Based)
- **MyFriendBen**: $50,000 - Direct beneficiary tool serving Colorado residents
- **Benefit Navigator**: $50,000 - Gates/Nava partnership, 7 US markets
- **Georgia Center for Opportunity**: $30,000 - US state-level research & connections
- **Atlanta Fed**: US Federal Reserve Bank Policy Rules Database collaboration
- **Prenatal-to-3 Policy Impact Center**: US policy document contribution, API user

## Evaluation Criteria (Per PBIF Guidelines)

### 1. Impact (25%)
- Addresses clear barriers to accessing US safety net programs (SNAP, Medicaid, TANF, etc.)
- Demonstrates measurable improvement for US beneficiaries and government staff
- Has plan to track and report impact within US jurisdictions

### 2. Responsible AI (20%)
- Prioritizes data privacy, transparency, fairness
- Identifies and mitigates risks like bias or misuse
- Clear governance structure

### 3. Technical & Practical Feasibility (20%)
- Technically sound and achievable within timeline
- Team has necessary expertise and partnerships
- Can integrate with existing US federal and state government systems

### 4. Strategic Alignment (20%)
- Represents opportunity that wouldn't manifest without catalytic funding
- Aligns with PBIF priority areas (administrative burden, benefits access)
- Builds on existing infrastructure appropriately

### 5. Shared Learning and Scale (15%)
- Clear plan for sharing findings
- Reasonable path to scalability
- Open source commitment

## Scoring Guidelines
- 90-100: Exceptional - Fund immediately with full amount
- 80-89: Strong - Fund with possible minor adjustments
- 70-79: Good - Consider funding with significant revisions
- 60-69: Fair - Major concerns, unlikely to fund
- Below 60: Does not meet criteria

## Context from Funder's Past Investments

### Social Safety Net Product Studio (2022)
- $13M initiative by Schmidt Futures, Ballmer Group, Gates Foundation
- Funded 12 teams improving benefits access through product development
- Focus on tools that scale to serve low-income families

### Recent Ballmer Group Investments
- **Georgetown Beeck Center** (2024): $8M for digital benefits infrastructure
- **Benefits Data Trust**: Multi-year support for benefits access
- **Code for America**: GetCalFresh and integrated benefits tools

### What Funders Value
Based on past investments, reviewers should consider:
1. **Direct government partnerships** - Not just advocacy
2. **Measurable efficiency gains** - Time/cost savings for agencies
3. **Open source infrastructure** - Reusable by multiple states
4. **AI responsibility** - Clear bias mitigation, transparency
5. **Sustainability** - Path to self-funding after grant period

## Red Flags to Watch For
- Lack of government buy-in
- Unrealistic technical promises
- No clear metrics for success
- Insufficient risk mitigation
- Team lacks relevant experience

## Simulation Notes
Each reviewer evaluation should:
1. Provide scores for each criterion (out of 20 or 25 points)
2. Include 2-3 strengths and 2-3 concerns
3. Ask clarifying questions for Round 3
4. Give overall funding recommendation
5. Suggest any conditions or modifications

Remember: PBIF funds $500K-$2M projects. Our request of $700K is on the lower end, leaving room for the committee to increase funding if they see exceptional merit.